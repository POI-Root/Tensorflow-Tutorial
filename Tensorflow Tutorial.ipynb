{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is running on Geforce GTX 1080Ti 12GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Basic Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # use second GPU\n",
    "\n",
    "seed = 2 # random seed\n",
    "model_dir = \"model/\" # folder for saving model and log\n",
    "resize_shape = (128, 128) # resized image size\n",
    "NUM_LABELS = 12 # number of labels\n",
    "BATCH_SIZE = 256 # number of images in one batch\n",
    "EPOCHS = 10\n",
    "SAVE_SUMMARY_STEPS = 100 # save summary to tensorboard - one step means one batch\n",
    "NUM_GPUS = 1 # number of GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "See Analyze.ipynb  \n",
    "dataset from: https://www.kaggle.com/c/plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (4630, 128, 128, 3) (4630,)\n",
      "Validation set (120, 128, 128, 3) (120,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = 'train_val10_{1}*{1}_seed{0}.pickle'.format(seed, resize_shape[0])\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    train_dataset = train_dataset.astype(\"float32\")\n",
    "    valid_dataset = valid_dataset.astype(\"float32\")\n",
    "    train_dataset /= 255\n",
    "    valid_dataset /= 255\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed',\n",
       "       'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize',\n",
       "       'Scentless Mayweed', 'Shepherds Purse',\n",
       "       'Small-flowered Cranesbill', 'Sugar beet'], dtype='<U25')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "valid_labels = encoder.transform(valid_labels)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_dataset)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "generator = datagen.flow(train_dataset, train_labels,\n",
    "                         batch_size=1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn_keras(generator):\n",
    "    gen_fn = lambda: generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(gen_fn, (tf.float32, tf.int64))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    print(\"output feature:\", features.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model (Original Version)\n",
    "1. original version can not do image aumentation by `tf.keras.preprocessing.image`, because `dataset` input is **Tensor** type, however `tf.keras.preprocessing.image` input is **numpy** type  \n",
    "    * Solution 1  - Running time: 181.727 sec per 100 steps (batch_size=256)\n",
    "    ```python\n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                image = tf.keras.preprocessing.image.random_rotation(np.array(image), 30, row_axis=0, col_axis=1, channel_axis=2)\n",
    "                image = tf.keras.preprocessing.image.random_shift(image, 0.1, 0.1, row_axis=0, col_axis=1, channel_axis=2)\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    ```\n",
    "    * Solution 2 - Running time: 105.140 sec per 100 steps (batch_size=256)  \n",
    "    use `tf.keras.preprocessing.image.ImageDataGenerator`  \n",
    "    Reference: http://www.scsk.jp/product/oss/tec_guide/tensorflow_keras/1_tensorflow_keras3_3.html\n",
    "2. `tf.data.Dataset.prefetch` for speed optimization. Pre fetch and load data when GPU is running, i.e. CPU is always running  \n",
    "    Set **`None`** for tensorflow to choose how many data to pre-load for opitimal speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    def _image_augmentation(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(features, labels), (tf.float32, tf.int64))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.map(_image_augmentation)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    print(\"output feature:\", features.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Evaluation Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(features, labels), (tf.float32, tf.int64))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "**Remember: Do batch normalization in training mode, but not in evaluation and prediction mode**  \n",
    "This model Structure based on VGG net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(features, training):\n",
    "    \n",
    "    # Block 1\n",
    "    features = tf.layers.conv2d(features, filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block1_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block1_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block1_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block1_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block1_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block1_relu2\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block1_maxPool1\")\n",
    "    \n",
    "    # Block 2\n",
    "    features = tf.layers.conv2d(features, filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block2_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block2_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block2_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block2_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block2_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block2_relu2\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block2_maxPool1\")\n",
    "    \n",
    "    # Block 3\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu2\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv3\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch3\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu3\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block3_maxPool1\")\n",
    "    \n",
    "    # Block 4\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu2\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv3\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch3\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu3\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block4_maxPool1\")\n",
    "    \n",
    "    features = tf.layers.flatten(features)\n",
    "    \n",
    "    # Fully Connected\n",
    "    features = tf.layers.dense(features, units=64, activation=tf.nn.relu, name=\"dense1\")\n",
    "    features = tf.layers.dropout(features, rate=0.5, name=\"dropout1\")\n",
    "    features = tf.layers.dense(features, units=32, activation=tf.nn.relu, name=\"dense2\")\n",
    "    features = tf.layers.dropout(features, rate=0.5, name=\"dropout2\")\n",
    "    logits = tf.layers.dense(features, units=NUM_LABELS, name=\"output\")\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function for tf.Estimator\n",
    "To save model for tensorflow serving, set **`export_outputs`** parameter in prediction mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # to save model for tensorflow serving\n",
    "    if isinstance(features, dict):\n",
    "        features = features['image']\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "    else:\n",
    "        training = False\n",
    "    \n",
    "    logits = model_structure(features, training)\n",
    "    \n",
    "    predicted_class = tf.argmax(logits, axis=1)\n",
    "    \n",
    "    # Prediction mode for tensorflow serving\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_class[:, tf.newaxis],\n",
    "            \"probability\": tf.nn.softmax(logits),\n",
    "            \"logits\": logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs={ \n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)})\n",
    "    \n",
    "    # calculate cross entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    def _f1_score(labels, predictions, class_id):\n",
    "        \"\"\"\n",
    "        Reference: https://stackoverflow.com/questions/45603956/class-wise-precision-and-recall-for-multi-class-classification-in-tensorflow\n",
    "        \"\"\"\n",
    "        precision = tf.metrics.precision_at_k(labels, predictions, 1, class_id)\n",
    "        recall = tf.metrics.recall_at_k(labels, predictions, 1, class_id)\n",
    "        f1_score = 2 * (precision[0] * recall[0]) / (precision[0] + recall[0])\n",
    "        f1_score_op = 2 * (precision[1] * recall[1]) / (precision[1] + recall[1])\n",
    "        return (f1_score, f1_score_op)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_class, name=\"accuracy\")\n",
    "    f1_score_BlackGrass = _f1_score(labels=labels, predictions=logits, class_id=0)\n",
    "    metrics = {\"accuracy\" : accuracy, \"f1_score_BlackGrass\" : f1_score_BlackGrass}\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    tf.summary.scalar(\"f1_score_BlackGrass\", f1_score_BlackGrass[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        \n",
    "        # for multiple GPUs\n",
    "        # optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        \n",
    "        # for batch normalization, tell tensorflow update batch normalization mean and variance\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "            \n",
    "        # normal version\n",
    "        #train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        # monitor trianing information\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss, \n",
    "                                                   \"accuracy\" : accuracy[1], \n",
    "                                                   \"f1_score_BlackGrass\" : f1_score_BlackGrass[1]}, \n",
    "                                                  every_n_iter=SAVE_SUMMARY_STEPS)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Multiple GPU (Parallel Computing)\n",
    "Testing, not stable version  \n",
    "Evaluation is not yet distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_strategy(num_gpus, all_reduce_alg=None):\n",
    "    \"\"\"Return a DistributionStrategy for running the model.\n",
    "    Args:\n",
    "    num_gpus: Number of GPUs to run this model.\n",
    "    all_reduce_alg: Specify which algorithm to use when performing all-reduce.\n",
    "      See tf.contrib.distribute.AllReduceCrossTowerOps for available algorithms.\n",
    "      If None, DistributionStrategy will choose based on device topology.\n",
    "    Returns:\n",
    "    tf.contrib.distribute.DistibutionStrategy object.\n",
    "    \"\"\"\n",
    "    if num_gpus == 0:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:CPU:0\")\n",
    "    elif num_gpus == 1:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:GPU:0\")\n",
    "    else:\n",
    "        if all_reduce_alg:\n",
    "            return tf.contrib.distribute.MirroredStrategy(\n",
    "                num_gpus=num_gpus,\n",
    "                cross_tower_ops=tf.contrib.distribute.AllReduceCrossTowerOps(\n",
    "                    all_reduce_alg, num_packs=num_gpus))\n",
    "        else:\n",
    "            return tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Runing Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'model_test/', '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_global_id_in_cluster': 0, '_num_ps_replicas': 0, '_is_chief': True, '_evaluation_master': '', '_tf_random_seed': 2, '_service': None, '_save_checkpoints_secs': 300, '_keep_checkpoint_every_n_hours': 10000, '_task_type': 'worker', '_save_summary_steps': 100, '_task_id': 0, '_master': '', '_device_fn': None, '_log_step_count_steps': 100, '_train_distribute': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7b134370b8>, '_save_checkpoints_steps': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.8\n",
      "  allow_growth: true\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "session_config.gpu_options.allow_growth = True\n",
    "config = tf.estimator.RunConfig(model_dir=model_dir, \n",
    "                                tf_random_seed=seed, \n",
    "                                save_summary_steps=SAVE_SUMMARY_STEPS, \n",
    "                                save_checkpoints_secs=300, \n",
    "                                session_config=session_config,\n",
    "                                keep_checkpoint_max=5, \n",
    "                                log_step_count_steps=100, )\n",
    "#                                train_distribute=get_distribution_strategy(NUM_GPUS)) #for mutiple GPUs\n",
    "clf = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after 300 secs (eval_spec.throttle_secs) or training is finished.\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.1715603, step = 0\n",
      "INFO:tensorflow:accuracy = 0.109375, f1_score_BlackGrass = nan, loss = 3.1715603\n",
      "INFO:tensorflow:global_step/sec: 0.987524\n",
      "INFO:tensorflow:loss = 1.4748855, step = 100 (101.266 sec)\n",
      "INFO:tensorflow:accuracy = 0.32421875, f1_score_BlackGrass = 0.08, loss = 1.4748855 (101.265 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.966839\n",
      "INFO:tensorflow:loss = 0.7085998, step = 200 (103.430 sec)\n",
      "INFO:tensorflow:accuracy = 0.4778646, f1_score_BlackGrass = 0.0909090909090909, loss = 0.7085998 (103.431 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 248 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.57910734.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:02:10\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-248\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:02:11\n",
      "INFO:tensorflow:Saving dict for global step 248: accuracy = 0.083333336, f1_score_BlackGrass = nan, global_step = 248, loss = 5.847232\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 248: model_test/model.ckpt-248\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-248\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 248 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.54984766, step = 248\n",
      "INFO:tensorflow:accuracy = 0.80078125, f1_score_BlackGrass = 0.26666666666666666, loss = 0.54984766\n",
      "INFO:tensorflow:global_step/sec: 0.940354\n",
      "INFO:tensorflow:loss = 0.41431245, step = 348 (106.345 sec)\n",
      "INFO:tensorflow:accuracy = 0.82421875, f1_score_BlackGrass = 0.47058823529411764, loss = 0.41431245 (106.345 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.954648\n",
      "INFO:tensorflow:loss = 0.2823116, step = 448 (104.751 sec)\n",
      "INFO:tensorflow:accuracy = 0.8463542, f1_score_BlackGrass = 0.48101265822784806, loss = 0.2823116 (104.751 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 491 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.15171623.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:07:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-491\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:07:15\n",
      "INFO:tensorflow:Saving dict for global step 491: accuracy = 0.175, f1_score_BlackGrass = nan, global_step = 491, loss = 5.668578\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 491: model_test/model.ckpt-491\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-491\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 491 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.30473208, step = 491\n",
      "INFO:tensorflow:accuracy = 0.88671875, f1_score_BlackGrass = 0.5714285714285714, loss = 0.30473208\n",
      "INFO:tensorflow:global_step/sec: 0.959069\n",
      "INFO:tensorflow:loss = 0.20250683, step = 591 (104.271 sec)\n",
      "INFO:tensorflow:accuracy = 0.9082031, f1_score_BlackGrass = 0.6122448979591837, loss = 0.20250683 (104.271 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.956348\n",
      "INFO:tensorflow:loss = 0.22412041, step = 691 (104.563 sec)\n",
      "INFO:tensorflow:accuracy = 0.90625, f1_score_BlackGrass = 0.5747126436781609, loss = 0.22412041 (104.563 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 735 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.1670202.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:12:18\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-735\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:12:18\n",
      "INFO:tensorflow:Saving dict for global step 735: accuracy = 0.8, f1_score_BlackGrass = 0.5333333333333333, global_step = 735, loss = 0.70873433\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 735: model_test/model.ckpt-735\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-735\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 735 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.118519545, step = 735\n",
      "INFO:tensorflow:accuracy = 0.96875, f1_score_BlackGrass = 0.88, loss = 0.118519545\n",
      "INFO:tensorflow:global_step/sec: 0.973493\n",
      "INFO:tensorflow:loss = 0.14456443, step = 835 (102.725 sec)\n",
      "INFO:tensorflow:accuracy = 0.9511719, f1_score_BlackGrass = 0.7924528301886792, loss = 0.14456443 (102.726 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.944141\n",
      "INFO:tensorflow:loss = 0.11364434, step = 935 (105.917 sec)\n",
      "INFO:tensorflow:accuracy = 0.9557292, f1_score_BlackGrass = 0.7999999999999999, loss = 0.11364434 (105.916 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 983 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.12708642.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:17:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-983\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:17:22\n",
      "INFO:tensorflow:Saving dict for global step 983: accuracy = 0.875, f1_score_BlackGrass = 0.8000000000000002, global_step = 983, loss = 0.38276443\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 983: model_test/model.ckpt-983\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-983\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 983 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.13232844, step = 983\n",
      "INFO:tensorflow:accuracy = 0.9453125, f1_score_BlackGrass = 0.689655172413793, loss = 0.13232844\n",
      "INFO:tensorflow:global_step/sec: 0.965115\n",
      "INFO:tensorflow:loss = 0.11381505, step = 1083 (103.618 sec)\n",
      "INFO:tensorflow:accuracy = 0.953125, f1_score_BlackGrass = 0.7234042553191491, loss = 0.11381505 (103.617 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96538\n",
      "INFO:tensorflow:loss = 0.07786863, step = 1183 (103.586 sec)\n",
      "INFO:tensorflow:accuracy = 0.9609375, f1_score_BlackGrass = 0.7837837837837838, loss = 0.07786863 (103.585 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1231 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.102639824.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:22:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1231\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:22:26\n",
      "INFO:tensorflow:Saving dict for global step 1231: accuracy = 0.925, f1_score_BlackGrass = 0.8000000000000002, global_step = 1231, loss = 0.35684273\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1231: model_test/model.ckpt-1231\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1231\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1231 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.110963956, step = 1231\n",
      "INFO:tensorflow:accuracy = 0.96875, f1_score_BlackGrass = 0.823529411764706, loss = 0.110963956\n",
      "INFO:tensorflow:global_step/sec: 0.965968\n",
      "INFO:tensorflow:loss = 0.08632525, step = 1331 (103.527 sec)\n",
      "INFO:tensorflow:accuracy = 0.9628906, f1_score_BlackGrass = 0.819672131147541, loss = 0.08632525 (103.526 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.96846\n",
      "INFO:tensorflow:loss = 0.13437124, step = 1431 (103.256 sec)\n",
      "INFO:tensorflow:accuracy = 0.9583333, f1_score_BlackGrass = 0.8163265306122449, loss = 0.13437124 (103.256 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1482 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.053688265.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:27:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1482\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:27:29\n",
      "INFO:tensorflow:Saving dict for global step 1482: accuracy = 0.85833335, f1_score_BlackGrass = 0.8421052631578948, global_step = 1482, loss = 0.5222404\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1482: model_test/model.ckpt-1482\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1482\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1482 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.051160842, step = 1482\n",
      "INFO:tensorflow:accuracy = 0.984375, f1_score_BlackGrass = 0.9285714285714286, loss = 0.051160842\n",
      "INFO:tensorflow:global_step/sec: 0.948613\n",
      "INFO:tensorflow:loss = 0.11518221, step = 1582 (105.419 sec)\n",
      "INFO:tensorflow:accuracy = 0.96484375, f1_score_BlackGrass = 0.8831168831168831, loss = 0.11518221 (105.419 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.961819\n",
      "INFO:tensorflow:loss = 0.072291315, step = 1682 (103.971 sec)\n",
      "INFO:tensorflow:accuracy = 0.96744794, f1_score_BlackGrass = 0.8828828828828829, loss = 0.072291315 (103.970 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1728 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.057943963.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:32:32\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1728\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:32:32\n",
      "INFO:tensorflow:Saving dict for global step 1728: accuracy = 0.9, f1_score_BlackGrass = 0.8000000000000002, global_step = 1728, loss = 0.42632002\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1728: model_test/model.ckpt-1728\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1728\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1728 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 0.04805626, step = 1728\n",
      "INFO:tensorflow:accuracy = 0.984375, f1_score_BlackGrass = 0.9411764705882353, loss = 0.04805626\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.07022004.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-08-15-06:34:30\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-08-15-06:34:31\n",
      "INFO:tensorflow:Saving dict for global step 1800: accuracy = 0.9166667, f1_score_BlackGrass = 0.8571428571428572, global_step = 1800, loss = 0.3959397\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: model_test/model.ckpt-1800\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.9166667,\n",
       "  'f1_score_BlackGrass': 0.8571428571428572,\n",
       "  'global_step': 1800,\n",
       "  'loss': 0.3959397},\n",
       " [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(lambda:train_input_fn_keras(generator), max_steps=1800)\n",
    "eval_spec = tf.estimator.EvalSpec(lambda:eval_input_fn(valid_dataset, valid_labels), throttle_secs=300)\n",
    "tf.estimator.train_and_evaluate(clf, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for Tensorflow Serving\n",
    "Can not save model after **predict**, because `Graph` is finalized and cannot be modified  \n",
    "You can assign which model to be saved by `checkpoint_path` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classify']\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-3600\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1534315492'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved_model/1534315492'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "image = tf.placeholder(tf.float32, shape=[None, 128, 128, 3], name='image')\n",
    "# input receiver\n",
    "input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "    'image': image,\n",
    "})\n",
    "\n",
    "clf.export_savedmodel(\"saved_model/\", input_fn, checkpoint_path=\"model/model.ckpt-3600\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and predict\n",
    "Estimator predict method return **generator** type, so if you want to get all predictions please use for loop  \n",
    "```python\n",
    "for result in results:\n",
    "    print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-3600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([8]),\n",
       " 'logits': array([ 6.0683594 ,  2.4238575 , -0.16211988,  8.492256  ,  5.0945616 ,\n",
       "        -5.9899054 , -2.91537   ,  2.8907135 , 28.753607  , 12.423214  ,\n",
       "        -1.8675876 , 11.166189  ], dtype=float32),\n",
       " 'probability': array([1.4057955e-10, 3.6739630e-12, 2.7673176e-13, 1.5871104e-09,\n",
       "        5.3089269e-11, 8.1486327e-16, 1.7633500e-14, 5.8598668e-12,\n",
       "        9.9999988e-01, 8.0872425e-08, 5.0278690e-14, 2.3008139e-08],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict(lambda: eval_input_fn(valid_dataset, valid_labels), checkpoint_path=\"model/model.ckpt-3600\")\n",
    "next(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from `Estimator.export_savedmodel`\n",
    "Reference: https://qiita.com/parkkiung123/items/13adb482860f356f97f3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1534315492/variables/variables\n",
      "[ 8  8  8  8  8  8  8  8  8  8  4 11  5 11 11 11 11 11 11 11  4  4  4  4\n",
      "  4  4  4  4  4  4  1  1  1  1  1  1  1  1  1  1 10 10 10 10 10 10 10 10\n",
      " 10 10  6  6  0  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  9  9\n",
      "  9  9  9  8  9  9  9  9  3  3  3  3  3  3  3  3  3  3  5  5  5  5  5  5\n",
      "  5  5  5  5  2  2  2  3  2  2  2  2  2  2  6  0  0  0  6  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "export_dir = 'saved_model/1534315492'\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # saved_model load\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # input\n",
    "    i = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "    # output\n",
    "    r = sess.graph.get_tensor_by_name(\"ArgMax:0\")\n",
    "    print(sess.run(r, feed_dict={i:valid_dataset}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Visualization\n",
    "Reference: https://github.com/InFoCusp/tf_cnnvis  \n",
    "Although you put multiple images, it only draws one image for visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/1534315492/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for block1_relu1 layer. Time taken = 0.088374 s\n",
      "Reconstruction Completed for block1_relu2 layer. Time taken = 0.093636 s\n",
      "Reconstruction Completed for block2_relu1 layer. Time taken = 0.065797 s\n",
      "Reconstruction Completed for block2_relu2 layer. Time taken = 0.080462 s\n",
      "Reconstruction Completed for block3_relu1 layer. Time taken = 0.075889 s\n",
      "Reconstruction Completed for block3_relu2 layer. Time taken = 0.072415 s\n",
      "Reconstruction Completed for block3_relu3 layer. Time taken = 0.063054 s\n",
      "Reconstruction Completed for block4_relu1 layer. Time taken = 0.058360 s\n",
      "Reconstruction Completed for block4_relu2 layer. Time taken = 0.058211 s\n",
      "Reconstruction Completed for block4_relu3 layer. Time taken = 0.060813 s\n",
      "Reconstruction Completed for dense1/Relu layer. Time taken = 0.057181 s\n",
      "Reconstruction Completed for dense2/Relu layer. Time taken = 0.053209 s\n",
      "Reconstruction Completed for block1_maxPool1/MaxPool layer. Time taken = 0.054758 s\n",
      "Reconstruction Completed for block2_maxPool1/MaxPool layer. Time taken = 0.045888 s\n",
      "Reconstruction Completed for block3_maxPool1/MaxPool layer. Time taken = 0.053312 s\n",
      "Reconstruction Completed for block4_maxPool1/MaxPool layer. Time taken = 0.056808 s\n",
      "Reconstruction Completed for block1_conv1/Conv2D layer. Time taken = 0.130368 s\n",
      "Reconstruction Completed for block1_conv2/Conv2D layer. Time taken = 0.111238 s\n",
      "Reconstruction Completed for block2_conv1/Conv2D layer. Time taken = 0.071046 s\n",
      "Reconstruction Completed for block2_conv2/Conv2D layer. Time taken = 0.073249 s\n",
      "Reconstruction Completed for block3_conv1/Conv2D layer. Time taken = 0.054093 s\n",
      "Reconstruction Completed for block3_conv2/Conv2D layer. Time taken = 0.053768 s\n",
      "Reconstruction Completed for block3_conv3/Conv2D layer. Time taken = 0.066101 s\n",
      "Reconstruction Completed for block4_conv1/Conv2D layer. Time taken = 0.049992 s\n",
      "Reconstruction Completed for block4_conv2/Conv2D layer. Time taken = 0.052964 s\n",
      "Reconstruction Completed for block4_conv3/Conv2D layer. Time taken = 0.059382 s\n",
      "Total Time = 2.184467\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# activation visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = tf.placeholder(tf.float32, shape=[None, 128, 128, 3], name=\"image\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # with sess_graph_path = None, the default Session will be used for visualization.\n",
    "    is_success = tf_cnnvis.activation_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                    layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                    path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ./saved_model/1534315492/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for block1_relu1 layer. Time taken = 0.490225 s\n",
      "Reconstruction Completed for block1_relu2 layer. Time taken = 0.646960 s\n",
      "Reconstruction Completed for block2_relu1 layer. Time taken = 1.032364 s\n",
      "Reconstruction Completed for block2_relu2 layer. Time taken = 1.264522 s\n",
      "Reconstruction Completed for block3_relu1 layer. Time taken = 2.810148 s\n",
      "Reconstruction Completed for block3_relu2 layer. Time taken = 2.557273 s\n",
      "Reconstruction Completed for block3_relu3 layer. Time taken = 3.597884 s\n",
      "Reconstruction Completed for block4_relu1 layer. Time taken = 4.339543 s\n",
      "Reconstruction Completed for block4_relu2 layer. Time taken = 4.731924 s\n",
      "Reconstruction Completed for block4_relu3 layer. Time taken = 4.582934 s\n",
      "Reconstruction Completed for dense1/Relu layer. Time taken = 2.806232 s\n",
      "Reconstruction Completed for dense2/Relu layer. Time taken = 2.420002 s\n",
      "Reconstruction Completed for block1_maxPool1/MaxPool layer. Time taken = 1.618889 s\n",
      "Reconstruction Completed for block2_maxPool1/MaxPool layer. Time taken = 2.168401 s\n",
      "Reconstruction Completed for block3_maxPool1/MaxPool layer. Time taken = 4.103661 s\n",
      "Reconstruction Completed for block4_maxPool1/MaxPool layer. Time taken = 6.008372 s\n",
      "Reconstruction Completed for block1_conv1/Conv2D layer. Time taken = 1.679418 s\n",
      "Reconstruction Completed for block1_conv2/Conv2D layer. Time taken = 1.915416 s\n",
      "Reconstruction Completed for block2_conv1/Conv2D layer. Time taken = 2.289315 s\n",
      "Reconstruction Completed for block2_conv2/Conv2D layer. Time taken = 2.451233 s\n",
      "Reconstruction Completed for block3_conv1/Conv2D layer. Time taken = 3.596914 s\n",
      "Reconstruction Completed for block3_conv2/Conv2D layer. Time taken = 3.715561 s\n",
      "Reconstruction Completed for block3_conv3/Conv2D layer. Time taken = 4.122712 s\n",
      "Reconstruction Completed for block4_conv1/Conv2D layer. Time taken = 4.680316 s\n",
      "Reconstruction Completed for block4_conv2/Conv2D layer. Time taken = 5.365810 s\n",
      "Reconstruction Completed for block4_conv3/Conv2D layer. Time taken = 5.696917 s\n",
      "Total Time = 81.261014\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "tf.reset_default_graph()\n",
    "\n",
    "# deconv visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = tf.placeholder(tf.float32, shape=[None, 128, 128, 3], name=\"image\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    is_success = tf_cnnvis.deconv_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
