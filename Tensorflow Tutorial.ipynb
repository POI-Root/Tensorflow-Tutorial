{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is running on Geforce GTX 1080Ti 12GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Basic Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # use second GPU\n",
    "\n",
    "seed = 2 # random seed\n",
    "model_dir = \"model_test/\" # folder for saving model and log\n",
    "resize_shape = (128, 128) # resized image size\n",
    "NUM_LABELS = 12 # number of labels\n",
    "BATCH_SIZE = 256 # number of images in one batch\n",
    "EPOCHS = 10\n",
    "SAVE_SUMMARY_STEPS = 100 # save summary to tensorboard - one step means one batch\n",
    "NUM_GPUS = 1 # number of GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "See Analyze.ipynb  \n",
    "dataset from: https://www.kaggle.com/c/plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (4630, 128, 128, 3) (4630,)\n",
      "Validation set (120, 128, 128, 3) (120,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = 'train_val10_{1}*{1}_seed{0}.pickle'.format(seed, resize_shape[0])\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    train_dataset = train_dataset.astype(\"float32\")\n",
    "    valid_dataset = valid_dataset.astype(\"float32\")\n",
    "    train_dataset /= 255\n",
    "    valid_dataset /= 255\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed',\n",
       "       'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize',\n",
       "       'Scentless Mayweed', 'Shepherds Purse',\n",
       "       'Small-flowered Cranesbill', 'Sugar beet'], dtype='<U25')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "valid_labels = encoder.transform(valid_labels)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_dataset)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "generator = datagen.flow(train_dataset, train_labels,\n",
    "                         batch_size=1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn_keras(generator):\n",
    "    gen_fn = lambda: generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(gen_fn, (tf.float32, tf.int64))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    print(\"output feature:\", features.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model (Original Version)\n",
    "1. original version can not do image aumentation by `tf.keras.preprocessing.image`, because `dataset` input is **Tensor** type, however `tf.keras.preprocessing.image` input is **numpy** type  \n",
    "    * Solution 1  - Running time: 181.727 sec per 100 steps (batch_size=256)\n",
    "    ```python\n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                image = tf.keras.preprocessing.image.random_rotation(np.array(image), 30, row_axis=0, col_axis=1, channel_axis=2)\n",
    "                image = tf.keras.preprocessing.image.random_shift(image, 0.1, 0.1, row_axis=0, col_axis=1, channel_axis=2)\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    ```\n",
    "    * Solution 2 - Running time: 105.140 sec per 100 steps (batch_size=256)  \n",
    "    use `tf.keras.preprocessing.image.ImageDataGenerator`  \n",
    "    Reference: http://www.scsk.jp/product/oss/tec_guide/tensorflow_keras/1_tensorflow_keras3_3.html\n",
    "2. `tf.data.Dataset.prefetch` for speed optimization. Pre fetch and load data when GPU is running, i.e. CPU is always running  \n",
    "    Set **`None`** for tensorflow to choose how many data to pre-load for opitimal speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(features, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    def _image_augmentation(image, label):\n",
    "        image = tf.image.random_flip_left_right(image)\n",
    "        image = tf.image.random_flip_up_down(image)\n",
    "        return image, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(features, labels), (tf.float32, tf.int64))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.map(_image_augmentation)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    print(\"output feature:\", features.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Evaluation Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(features, labels), (tf.float32, tf.int64))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "**Remember: Do batch normalization in training mode, but not in evaluation and prediction mode**  \n",
    "This model Structure based on VGG net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_structure(features, training):\n",
    "    \n",
    "    # Block 1\n",
    "    features = tf.layers.conv2d(features, filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block1_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block1_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block1_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=32, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block1_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block1_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block1_relu2\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block1_maxPool1\")\n",
    "    \n",
    "    # Block 2\n",
    "    features = tf.layers.conv2d(features, filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block2_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block2_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block2_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=64, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block2_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block2_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block2_relu2\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block2_maxPool1\")\n",
    "    \n",
    "    # Block 3\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu2\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block3_conv3\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block3_batch3\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block3_relu3\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block3_maxPool1\")\n",
    "    \n",
    "    # Block 4\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv1\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch1\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu1\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv2\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch2\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu2\")\n",
    "    features = tf.layers.conv2d(features, filters=128, kernel_size=(3, 3), strides=(1, 1), padding=\"same\", name=\"block4_conv3\")\n",
    "    features = tf.layers.batch_normalization(features, axis=-1, name=\"block4_batch3\", training=training)\n",
    "    features = tf.nn.relu(features, name=\"block4_relu3\")\n",
    "    features = tf.layers.max_pooling2d(features, pool_size=(2, 2), strides=(2, 2), name=\"block4_maxPool1\")\n",
    "    \n",
    "    features = tf.layers.flatten(features)\n",
    "    \n",
    "    # Fully Connected\n",
    "    features = tf.layers.dense(features, units=64, activation=tf.nn.relu, name=\"dense1\")\n",
    "    features = tf.layers.dropout(features, rate=0.5, name=\"dropout1\")\n",
    "    features = tf.layers.dense(features, units=32, activation=tf.nn.relu, name=\"dense2\")\n",
    "    features = tf.layers.dropout(features, rate=0.5, name=\"dropout2\")\n",
    "    logits = tf.layers.dense(features, units=NUM_LABELS, name=\"output\")\n",
    "    \n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function for tf.Estimator\n",
    "To save model for tensorflow serving, set **`export_outputs`** parameter in prediction mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # to save model for tensorflow serving\n",
    "    if isinstance(features, dict):\n",
    "        features = features['image']\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "    else:\n",
    "        training = False\n",
    "    \n",
    "    logits = model_structure(features, training)\n",
    "    \n",
    "    predicted_class = tf.argmax(logits, axis=1)\n",
    "    \n",
    "    # Prediction mode for tensorflow serving\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_class[:, tf.newaxis],\n",
    "            \"probability\": tf.nn.softmax(logits),\n",
    "            \"logits\": logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs={ \n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)})\n",
    "    \n",
    "    # calculate cross entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    def _f1_score(labels, predictions, class_id):\n",
    "        \"\"\"\n",
    "        Reference: https://stackoverflow.com/questions/45603956/class-wise-precision-and-recall-for-multi-class-classification-in-tensorflow\n",
    "        \"\"\"\n",
    "        precision = tf.metrics.precision_at_k(labels, predictions, 1, class_id)\n",
    "        recall = tf.metrics.recall_at_k(labels, predictions, 1, class_id)\n",
    "        f1_score = 2 * (precision[0] * recall[0]) / (precision[0] + recall[0])\n",
    "        f1_score_op = 2 * (precision[1] * recall[1]) / (precision[1] + recall[1])\n",
    "        return (f1_score, f1_score_op)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_class, name=\"accuracy\")\n",
    "    f1_score_BlackGrass = _f1_score(labels=labels, predictions=logits, class_id=0)\n",
    "    metrics = {\"accuracy\" : accuracy, \"f1_score_BlackGrass\" : f1_score_BlackGrass}\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    tf.summary.scalar(\"f1_score_BlackGrass\", f1_score_BlackGrass[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        \n",
    "        # for multiple GPUs\n",
    "        # optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        \n",
    "        # for batch normalization, tell tensorflow update batch normalization mean and variance\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "            \n",
    "        # normal version\n",
    "        #train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        # monitor trianing information\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss, \n",
    "                                                   \"accuracy\" : accuracy[1], \n",
    "                                                   \"f1_score_BlackGrass\" : f1_score_BlackGrass[1]}, \n",
    "                                                  every_n_iter=SAVE_SUMMARY_STEPS)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Multiple GPU (Parallel Computing)\n",
    "Testing, not stable version  \n",
    "Evaluation is not yet distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_strategy(num_gpus, all_reduce_alg=None):\n",
    "    \"\"\"Return a DistributionStrategy for running the model.\n",
    "    Args:\n",
    "    num_gpus: Number of GPUs to run this model.\n",
    "    all_reduce_alg: Specify which algorithm to use when performing all-reduce.\n",
    "      See tf.contrib.distribute.AllReduceCrossTowerOps for available algorithms.\n",
    "      If None, DistributionStrategy will choose based on device topology.\n",
    "    Returns:\n",
    "    tf.contrib.distribute.DistibutionStrategy object.\n",
    "    \"\"\"\n",
    "    if num_gpus == 0:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:CPU:0\")\n",
    "    elif num_gpus == 1:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:GPU:0\")\n",
    "    else:\n",
    "        if all_reduce_alg:\n",
    "            return tf.contrib.distribute.MirroredStrategy(\n",
    "                num_gpus=num_gpus,\n",
    "                cross_tower_ops=tf.contrib.distribute.AllReduceCrossTowerOps(\n",
    "                    all_reduce_alg, num_packs=num_gpus))\n",
    "        else:\n",
    "            return tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Runing Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_global_id_in_cluster': 0, '_task_id': 0, '_num_ps_replicas': 0, '_model_dir': 'model_test/', '_keep_checkpoint_every_n_hours': 10000, '_keep_checkpoint_max': 5, '_num_worker_replicas': 1, '_is_chief': True, '_save_checkpoints_steps': None, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_task_type': 'worker', '_service': None, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.8\n",
      "  allow_growth: true\n",
      "}\n",
      ", '_master': '', '_tf_random_seed': 2, '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbba6158198>, '_save_checkpoints_secs': 300, '_save_summary_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "session_config.gpu_options.allow_growth = True\n",
    "config = tf.estimator.RunConfig(model_dir=model_dir, \n",
    "                                tf_random_seed=seed, \n",
    "                                save_summary_steps=SAVE_SUMMARY_STEPS, \n",
    "                                save_checkpoints_secs=300, \n",
    "                                session_config=session_config,\n",
    "                                keep_checkpoint_max=5, \n",
    "                                log_step_count_steps=100, )\n",
    "#                                train_distribute=get_distribution_strategy(NUM_GPUS)) #for mutiple GPUs\n",
    "clf = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps None or save_checkpoints_secs 300.\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_test/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.8449872, step = 0\n",
      "INFO:tensorflow:accuracy = 0.09765625, f1_score_BlackGrass = nan, loss = 2.8449872\n",
      "INFO:tensorflow:global_step/sec: 0.984719\n",
      "INFO:tensorflow:loss = 1.4894128, step = 100 (101.554 sec)\n",
      "INFO:tensorflow:accuracy = 0.32421875, f1_score_BlackGrass = 0.1739130434782609, loss = 1.4894128 (101.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.977885\n",
      "INFO:tensorflow:loss = 0.61799383, step = 200 (102.262 sec)\n",
      "INFO:tensorflow:accuracy = 0.4778646, f1_score_BlackGrass = 0.10526315789473685, loss = 0.61799383 (102.262 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 252 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-03:54:54\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-252\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-03:54:55\n",
      "INFO:tensorflow:Saving dict for global step 252: accuracy = 0.083333336, f1_score_BlackGrass = nan, global_step = 252, loss = 6.919974\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 252: model_test/model.ckpt-252\n",
      "INFO:tensorflow:global_step/sec: 0.964815\n",
      "INFO:tensorflow:loss = 0.42496616, step = 300 (103.647 sec)\n",
      "INFO:tensorflow:accuracy = 0.578125, f1_score_BlackGrass = 0.1818181818181818, loss = 0.42496616 (103.647 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.954913\n",
      "INFO:tensorflow:loss = 0.37072527, step = 400 (104.722 sec)\n",
      "INFO:tensorflow:accuracy = 0.6390625, f1_score_BlackGrass = 0.40404040404040403, loss = 0.37072527 (104.722 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.963995\n",
      "INFO:tensorflow:loss = 0.26773995, step = 500 (103.734 sec)\n",
      "INFO:tensorflow:accuracy = 0.68619794, f1_score_BlackGrass = 0.4426229508196721, loss = 0.26773995 (103.735 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 542 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-03:59:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-542\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-03:59:56\n",
      "INFO:tensorflow:Saving dict for global step 542: accuracy = 0.325, f1_score_BlackGrass = nan, global_step = 542, loss = 4.2119994\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 542: model_test/model.ckpt-542\n",
      "INFO:tensorflow:global_step/sec: 0.977675\n",
      "INFO:tensorflow:loss = 0.21447252, step = 600 (102.284 sec)\n",
      "INFO:tensorflow:accuracy = 0.72209823, f1_score_BlackGrass = 0.5033112582781456, loss = 0.21447252 (102.283 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.965607\n",
      "INFO:tensorflow:loss = 0.20661512, step = 700 (103.562 sec)\n",
      "INFO:tensorflow:accuracy = 0.7475586, f1_score_BlackGrass = 0.5227272727272727, loss = 0.20661512 (103.562 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.977538\n",
      "INFO:tensorflow:loss = 0.14140394, step = 800 (102.298 sec)\n",
      "INFO:tensorflow:accuracy = 0.7690972, f1_score_BlackGrass = 0.54, loss = 0.14140394 (102.298 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 833 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-04:04:55\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-833\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-04:04:56\n",
      "INFO:tensorflow:Saving dict for global step 833: accuracy = 0.84166664, f1_score_BlackGrass = 0.631578947368421, global_step = 833, loss = 0.66710275\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 833: model_test/model.ckpt-833\n",
      "INFO:tensorflow:global_step/sec: 0.964679\n",
      "INFO:tensorflow:loss = 0.1605027, step = 900 (103.661 sec)\n",
      "INFO:tensorflow:accuracy = 0.78632814, f1_score_BlackGrass = 0.5479452054794521, loss = 0.1605027 (103.662 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.964828\n",
      "INFO:tensorflow:loss = 0.11245856, step = 1000 (103.645 sec)\n",
      "INFO:tensorflow:accuracy = 0.8022017, f1_score_BlackGrass = 0.5579399141630901, loss = 0.11245856 (103.643 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.956842\n",
      "INFO:tensorflow:loss = 0.10248587, step = 1100 (104.510 sec)\n",
      "INFO:tensorflow:accuracy = 0.81640625, f1_score_BlackGrass = 0.5891472868217054, loss = 0.10248587 (104.511 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1122 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-04:09:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1122\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-04:09:56\n",
      "INFO:tensorflow:Saving dict for global step 1122: accuracy = 0.8833333, f1_score_BlackGrass = 0.6666666666666666, global_step = 1122, loss = 0.37094766\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1122: model_test/model.ckpt-1122\n",
      "INFO:tensorflow:global_step/sec: 0.958323\n",
      "INFO:tensorflow:loss = 0.16760893, step = 1200 (104.349 sec)\n",
      "INFO:tensorflow:accuracy = 0.82572114, f1_score_BlackGrass = 0.5964912280701754, loss = 0.16760893 (104.350 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.965295\n",
      "INFO:tensorflow:loss = 0.10308328, step = 1300 (103.595 sec)\n",
      "INFO:tensorflow:accuracy = 0.8351005, f1_score_BlackGrass = 0.6250000000000001, loss = 0.10308328 (103.595 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.95688\n",
      "INFO:tensorflow:loss = 0.054264925, step = 1400 (104.507 sec)\n",
      "INFO:tensorflow:accuracy = 0.84505206, f1_score_BlackGrass = 0.6434782608695653, loss = 0.054264925 (104.508 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1411 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-04:14:56\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1411\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-04:14:57\n",
      "INFO:tensorflow:Saving dict for global step 1411: accuracy = 0.8666667, f1_score_BlackGrass = 0.6666666666666665, global_step = 1411, loss = 0.54692715\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1411: model_test/model.ckpt-1411\n",
      "INFO:tensorflow:global_step/sec: 0.977705\n",
      "INFO:tensorflow:loss = 0.0857517, step = 1500 (102.281 sec)\n",
      "INFO:tensorflow:accuracy = 0.85253906, f1_score_BlackGrass = 0.644808743169399, loss = 0.0857517 (102.281 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.964614\n",
      "INFO:tensorflow:loss = 0.058046196, step = 1600 (103.667 sec)\n",
      "INFO:tensorflow:accuracy = 0.8600643, f1_score_BlackGrass = 0.6683291770573567, loss = 0.058046196 (103.666 sec)\n",
      "INFO:tensorflow:global_step/sec: 0.961746\n",
      "INFO:tensorflow:loss = 0.049922474, step = 1700 (103.979 sec)\n",
      "INFO:tensorflow:accuracy = 0.86675346, f1_score_BlackGrass = 0.6791569086651055, loss = 0.049922474 (103.978 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1702 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-04:19:57\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1702\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-04:19:58\n",
      "INFO:tensorflow:Saving dict for global step 1702: accuracy = 0.93333334, f1_score_BlackGrass = 0.8421052631578948, global_step = 1702, loss = 0.23151535\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1702: model_test/model.ckpt-1702\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into model_test/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-12-04:21:40\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_test/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-12-04:21:40\n",
      "INFO:tensorflow:Saving dict for global step 1800: accuracy = 0.925, f1_score_BlackGrass = 0.9, global_step = 1800, loss = 0.40996316\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: model_test/model.ckpt-1800\n",
      "INFO:tensorflow:Loss for final step: 0.07194609.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.925,\n",
       "  'f1_score_BlackGrass': 0.9,\n",
       "  'global_step': 1800,\n",
       "  'loss': 0.40996316},\n",
       " [])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(lambda:train_input_fn_keras(generator), max_steps=1800)\n",
    "eval_spec = tf.estimator.EvalSpec(lambda:eval_input_fn(valid_dataset, valid_labels), throttle_secs=300)\n",
    "tf.estimator.train_and_evaluate(clf, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for Tensorflow Serving\n",
    "Can not save model after **predict**, because `Graph` is finalized and cannot be modified  \n",
    "You can assign which model to be saved by `checkpoint_path` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classify']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-3600\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1536729364'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved_model/1536729364'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "image = tf.placeholder(tf.float32, shape=[None, 128, 128, 3], name='image')\n",
    "# input receiver\n",
    "input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "    'image': image,\n",
    "})\n",
    "\n",
    "clf.export_savedmodel(\"saved_model/\", input_fn, checkpoint_path=\"model/model.ckpt-3600\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and predict\n",
    "Estimator predict method return **generator** type, so if you want to get all predictions please use for loop  \n",
    "```python\n",
    "for result in results:\n",
    "    print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model/model.ckpt-3600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([8]),\n",
       " 'logits': array([ 6.0683594 ,  2.4238575 , -0.16211988,  8.492256  ,  5.0945616 ,\n",
       "        -5.9899054 , -2.91537   ,  2.8907135 , 28.753607  , 12.423214  ,\n",
       "        -1.8675876 , 11.166189  ], dtype=float32),\n",
       " 'probability': array([1.4057955e-10, 3.6739630e-12, 2.7673176e-13, 1.5871104e-09,\n",
       "        5.3089269e-11, 8.1486327e-16, 1.7633500e-14, 5.8598668e-12,\n",
       "        9.9999988e-01, 8.0872425e-08, 5.0278690e-14, 2.3008139e-08],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict(lambda: eval_input_fn(valid_dataset, valid_labels), checkpoint_path=\"model/model.ckpt-3600\")\n",
    "next(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from `Estimator.export_savedmodel`\n",
    "Reference: https://qiita.com/parkkiung123/items/13adb482860f356f97f3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1534315492/variables/variables\n",
      "[ 8  8  8  8  8  8  8  8  8  8  4 11  5 11 11 11 11 11 11 11  4  4  4  4\n",
      "  4  4  4  4  4  4  1  1  1  1  1  1  1  1  1  1 10 10 10 10 10 10 10 10\n",
      " 10 10  6  6  0  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  9  9\n",
      "  9  9  9  8  9  9  9  9  3  3  3  3  3  3  3  3  3  3  5  5  5  5  5  5\n",
      "  5  5  5  5  2  2  2  3  2  2  2  2  2  2  6  0  0  0  6  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "export_dir = 'saved_model/1534315492'\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # saved_model load\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # input\n",
    "    i = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "    # output\n",
    "    r = sess.graph.get_tensor_by_name(\"ArgMax:0\")\n",
    "    print(sess.run(r, feed_dict={i:valid_dataset}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Visualization\n",
    "Reference: https://github.com/InFoCusp/tf_cnnvis  \n",
    "Although you put multiple images, it only draws one image for visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1534315492/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for block1_relu1 layer. Time taken = 0.104183 s\n",
      "Reconstruction Completed for block1_relu2 layer. Time taken = 0.113820 s\n",
      "Reconstruction Completed for block2_relu1 layer. Time taken = 0.072773 s\n",
      "Reconstruction Completed for block2_relu2 layer. Time taken = 0.078660 s\n",
      "Reconstruction Completed for block3_relu1 layer. Time taken = 0.077696 s\n",
      "Reconstruction Completed for block3_relu2 layer. Time taken = 0.081397 s\n",
      "Reconstruction Completed for block3_relu3 layer. Time taken = 0.062347 s\n",
      "Reconstruction Completed for block4_relu1 layer. Time taken = 0.059437 s\n",
      "Reconstruction Completed for block4_relu2 layer. Time taken = 0.056464 s\n",
      "Reconstruction Completed for block4_relu3 layer. Time taken = 0.055136 s\n",
      "Reconstruction Completed for dense1/Relu layer. Time taken = 0.052904 s\n",
      "Reconstruction Completed for dense2/Relu layer. Time taken = 0.052083 s\n",
      "Reconstruction Completed for block1_maxPool1/MaxPool layer. Time taken = 0.046057 s\n",
      "Reconstruction Completed for block2_maxPool1/MaxPool layer. Time taken = 0.049461 s\n",
      "Reconstruction Completed for block3_maxPool1/MaxPool layer. Time taken = 0.054776 s\n",
      "Reconstruction Completed for block4_maxPool1/MaxPool layer. Time taken = 0.053234 s\n",
      "Reconstruction Completed for block1_conv1/Conv2D layer. Time taken = 0.131753 s\n",
      "Reconstruction Completed for block1_conv2/Conv2D layer. Time taken = 0.110339 s\n",
      "Reconstruction Completed for block2_conv1/Conv2D layer. Time taken = 0.067561 s\n",
      "Reconstruction Completed for block2_conv2/Conv2D layer. Time taken = 0.069964 s\n",
      "Reconstruction Completed for block3_conv1/Conv2D layer. Time taken = 0.539477 s\n",
      "Reconstruction Completed for block3_conv2/Conv2D layer. Time taken = 0.086545 s\n",
      "Reconstruction Completed for block3_conv3/Conv2D layer. Time taken = 0.069148 s\n",
      "Reconstruction Completed for block4_conv1/Conv2D layer. Time taken = 0.053269 s\n",
      "Reconstruction Completed for block4_conv2/Conv2D layer. Time taken = 0.051521 s\n",
      "Reconstruction Completed for block4_conv3/Conv2D layer. Time taken = 0.054824 s\n",
      "Total Time = 2.770025\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "# activation visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # with sess_graph_path = None, the default Session will be used for visualization.\n",
    "    is_success = tf_cnnvis.activation_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                    layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                    path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1534315492/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for block1_relu1 layer. Time taken = 0.466542 s\n",
      "Reconstruction Completed for block1_relu2 layer. Time taken = 0.620932 s\n",
      "Reconstruction Completed for block2_relu1 layer. Time taken = 1.099149 s\n",
      "Reconstruction Completed for block2_relu2 layer. Time taken = 1.487387 s\n",
      "Reconstruction Completed for block3_relu1 layer. Time taken = 2.165719 s\n",
      "Reconstruction Completed for block3_relu2 layer. Time taken = 2.844257 s\n",
      "Reconstruction Completed for block3_relu3 layer. Time taken = 2.891150 s\n",
      "Reconstruction Completed for block4_relu1 layer. Time taken = 3.399595 s\n",
      "Reconstruction Completed for block4_relu2 layer. Time taken = 3.881448 s\n",
      "Reconstruction Completed for block4_relu3 layer. Time taken = 4.164734 s\n",
      "Reconstruction Completed for dense1/Relu layer. Time taken = 3.040706 s\n",
      "Reconstruction Completed for dense2/Relu layer. Time taken = 2.405533 s\n",
      "Reconstruction Completed for block1_maxPool1/MaxPool layer. Time taken = 1.752163 s\n",
      "Reconstruction Completed for block2_maxPool1/MaxPool layer. Time taken = 2.322251 s\n",
      "Reconstruction Completed for block3_maxPool1/MaxPool layer. Time taken = 3.840529 s\n",
      "Reconstruction Completed for block4_maxPool1/MaxPool layer. Time taken = 4.791328 s\n",
      "Reconstruction Completed for block1_conv1/Conv2D layer. Time taken = 1.616700 s\n",
      "Reconstruction Completed for block1_conv2/Conv2D layer. Time taken = 1.899459 s\n",
      "Reconstruction Completed for block2_conv1/Conv2D layer. Time taken = 2.316810 s\n",
      "Reconstruction Completed for block2_conv2/Conv2D layer. Time taken = 2.506830 s\n",
      "Reconstruction Completed for block3_conv1/Conv2D layer. Time taken = 3.697376 s\n",
      "Reconstruction Completed for block3_conv2/Conv2D layer. Time taken = 3.539015 s\n",
      "Reconstruction Completed for block3_conv3/Conv2D layer. Time taken = 3.959495 s\n",
      "Reconstruction Completed for block4_conv1/Conv2D layer. Time taken = 4.689037 s\n",
      "Reconstruction Completed for block4_conv2/Conv2D layer. Time taken = 5.587483 s\n",
      "Reconstruction Completed for block4_conv3/Conv2D layer. Time taken = 5.844115 s\n",
      "Total Time = 77.498804\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "# deconv visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    is_success = tf_cnnvis.deconv_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
