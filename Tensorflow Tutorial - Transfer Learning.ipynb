{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is running on Geforce GTX 1080Ti 12GB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Basic Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1' # use second GPU\n",
    "\n",
    "seed = 2 # random seed\n",
    "model_dir = \"model_transfer/\" # folder for saving model and log\n",
    "resize_shape = (128, 128) # resized image size\n",
    "NUM_LABELS = 12 # number of labels\n",
    "BATCH_SIZE = 256 # number of images in one batch\n",
    "EPOCHS = 10\n",
    "SAVE_SUMMARY_STEPS = 100 # save summary to tensorboard - one step means one batch\n",
    "NUM_GPUS = 1 # number of GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "See Analyze.ipynb  \n",
    "dataset from: https://www.kaggle.com/c/plant-seedlings-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set (4630, 128, 128, 3) (4630,)\n",
      "Validation set (120, 128, 128, 3) (120,)\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "pickle_file = 'train_val10_{1}*{1}_seed{0}.pickle'.format(seed, resize_shape[0])\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    train_dataset = save['train_dataset']\n",
    "    train_labels = save['train_labels']\n",
    "    valid_dataset = save['valid_dataset']\n",
    "    valid_labels = save['valid_labels']\n",
    "    train_dataset = train_dataset.astype(\"float32\")\n",
    "    valid_dataset = valid_dataset.astype(\"float32\")\n",
    "    train_dataset /= 255\n",
    "    valid_dataset /= 255\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Training set', train_dataset.shape, train_labels.shape)\n",
    "    print('Validation set', valid_dataset.shape, valid_labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Black-grass', 'Charlock', 'Cleavers', 'Common Chickweed',\n",
       "       'Common wheat', 'Fat Hen', 'Loose Silky-bent', 'Maize',\n",
       "       'Scentless Mayweed', 'Shepherds Purse',\n",
       "       'Small-flowered Cranesbill', 'Sugar beet'], dtype='<U25')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "train_labels = encoder.fit_transform(train_labels)\n",
    "valid_labels = encoder.transform(valid_labels)\n",
    "encoder.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Augmentation (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "            samplewise_center=False,  # set each sample mean to 0\n",
    "            featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "            samplewise_std_normalization=False,  # divide each input by its std\n",
    "            zca_whitening=False,  # apply ZCA whitening\n",
    "            rotation_range=180,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "            width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "            height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "            horizontal_flip=True,  # randomly flip images\n",
    "            vertical_flip=True)  # randomly flip images\n",
    "\n",
    "# Compute quantities required for feature-wise normalization\n",
    "# (std, mean, and principal components if ZCA whitening is applied).\n",
    "datagen.fit(train_dataset)\n",
    "\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "generator = datagen.flow(train_dataset, train_labels,\n",
    "                         batch_size=1, seed=seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model (Keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn_keras(generator):\n",
    "    gen_fn = lambda: generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(gen_fn, (tf.float32, tf.int64))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    print(\"output feature:\", features.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", features)\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Evaluation Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_input_fn(features, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(features, labels), (tf.float32, tf.int64))\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    features, labels = iterator.get_next()\n",
    "    features = tf.reshape(features, [-1, 128, 128, 3])\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "1. Tensorflow initail weight will use ```tf.global_variables_initializer()```, but it will destroy the pretrained weights. So save the pretrained weights\n",
    "2. Do not use keras way to get features on Keras pretrained model, i.e. ```features = model(feature)```. It will get duplicate graph  \n",
    "   Use the follwing code instead  \n",
    "   ```python\n",
    "   features = tf.identity(model.layers[-1].output, name='vgg16_output')\n",
    "   ```\n",
    "Reference: http://zachmoshe.com/2017/11/11/use-keras-models-with-tf.html \n",
    "2. Because we use Keras model, so running in Tensorflow original session will not get pretrained weights. Use ```tf.keras.backend.get_session()``` instead  \n",
    "Reference: https://github.com/keras-team/keras/issues/8438 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = \"imagenet\"\n",
    "def vgg16(features, training):\n",
    "    global weights\n",
    "    \n",
    "    with tf.variable_scope(\"vgg16\"):\n",
    "        model = tf.keras.applications.VGG16(include_top=False, weights=weights, input_tensor=features, input_shape=(128, 128, 3))\n",
    "    # Only load imagenet weight on the first run\n",
    "    if weights==\"imagenet\":\n",
    "        sess = tf.keras.backend.get_session()\n",
    "        vgg_weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='vgg16')\n",
    "        tf.train.Saver(vgg_weights).save(sess, \"pretrained_model/vgg16.ckpt\")\n",
    "        weights = None\n",
    "    features = tf.identity(model.layers[-1].output, name='vgg16_output')\n",
    "    features = tf.keras.layers.Flatten(name=\"flatten\")(features)\n",
    "    with tf.variable_scope(\"fine_tune\"):\n",
    "        features = tf.keras.layers.Dense(units=256, activation=tf.keras.activations.relu, name=\"dense1\")(features)\n",
    "        features = tf.keras.layers.Dropout(rate=0.5, name=\"dropout1\")(features)\n",
    "        features = tf.keras.layers.Dense(units=128, activation=tf.keras.activations.relu, name=\"dense2\")(features)\n",
    "        features = tf.keras.layers.Dropout(rate=0.5, name=\"dropout2\")(features)\n",
    "        logits = tf.keras.layers.Dense(units=NUM_LABELS, name=\"output\")(features)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function for tf.Estimator\n",
    "**Remember: set ```tf.keras.backend.set_learning_phase```. It will allow Keras model to update weights**  \n",
    "1. To save model for tensorflow serving, set **`export_outputs`** parameter in prediction mode\n",
    "2. If you want to freeze the imagenet weights, update the fully connected layer  \n",
    "   **Remember: preprocess input image via ```tf.keras.applications.vgg16.preprocess_input()```, make sure the weights is meaningful**   \n",
    "   Use follwing code instead  \n",
    "   ```python\n",
    "   train_op = optimizer.minimize(loss, var_list=tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES, scope='fine_tune'), global_step=tf.train.get_global_step())\n",
    "    ```     \n",
    "**Not freezing the imagenet weights is better than freezing the imagenet weights**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    # to save model for tensorflow serving\n",
    "    if isinstance(features, dict):\n",
    "        features = features['image']\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "        tf.keras.backend.set_learning_phase(True)\n",
    "    else:\n",
    "        training = False\n",
    "        tf.keras.backend.set_learning_phase(False)\n",
    "    \n",
    "    logits = vgg16(features, training)\n",
    "    \n",
    "    predicted_class = tf.argmax(logits, axis=1)\n",
    "    \n",
    "    # Prediction mode for tensorflow serving\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"class_ids\": predicted_class[:, tf.newaxis],\n",
    "            \"probability\": tf.nn.softmax(logits),\n",
    "            \"logits\": logits\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs={ \n",
    "            'classify': tf.estimator.export.PredictOutput(predictions)})\n",
    "    \n",
    "    # calculate cross entropy loss\n",
    "    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "    \n",
    "    def _f1_score(labels, predictions, class_id):\n",
    "        \"\"\"\n",
    "        Reference: https://stackoverflow.com/questions/45603956/class-wise-precision-and-recall-for-multi-class-classification-in-tensorflow\n",
    "        \"\"\"\n",
    "        precision = tf.metrics.precision_at_k(labels, predictions, 1, class_id)\n",
    "        recall = tf.metrics.recall_at_k(labels, predictions, 1, class_id)\n",
    "        f1_score = 2 * (precision[0] * recall[0]) / (precision[0] + recall[0])\n",
    "        f1_score_op = 2 * (precision[1] * recall[1]) / (precision[1] + recall[1])\n",
    "        return (f1_score, f1_score_op)\n",
    "    \n",
    "    accuracy = tf.metrics.accuracy(labels=labels, predictions=predicted_class, name=\"accuracy\")\n",
    "    f1_score_BlackGrass = _f1_score(labels=labels, predictions=logits, class_id=0)\n",
    "    metrics = {\"accuracy\" : accuracy, \"f1_score_BlackGrass\" : f1_score_BlackGrass}\n",
    "    tf.summary.scalar(\"accuracy\", accuracy[1])\n",
    "    tf.summary.scalar(\"f1_score_BlackGrass\", f1_score_BlackGrass[1])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=0.0001)\n",
    "        \n",
    "        # for multiple GPUs\n",
    "        # optimizer = tf.contrib.estimator.TowerOptimizer(optimizer)\n",
    "        \n",
    "        # for batch normalization, tell tensorflow update batch normalization mean and variance\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "            \n",
    "        # normal version\n",
    "        #train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "        \n",
    "        # monitor trianing information\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"loss\" : loss, \n",
    "                                                   \"accuracy\" : accuracy[1], \n",
    "                                                   \"f1_score_BlackGrass\" : f1_score_BlackGrass[1]}, \n",
    "                                                  every_n_iter=SAVE_SUMMARY_STEPS)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, eval_metric_ops=metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Multiple GPU (Parallel Computing)\n",
    "Testing, not stable version  \n",
    "Evaluation is not yet distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_strategy(num_gpus, all_reduce_alg=None):\n",
    "    \"\"\"Return a DistributionStrategy for running the model.\n",
    "    Args:\n",
    "    num_gpus: Number of GPUs to run this model.\n",
    "    all_reduce_alg: Specify which algorithm to use when performing all-reduce.\n",
    "      See tf.contrib.distribute.AllReduceCrossTowerOps for available algorithms.\n",
    "      If None, DistributionStrategy will choose based on device topology.\n",
    "    Returns:\n",
    "    tf.contrib.distribute.DistibutionStrategy object.\n",
    "    \"\"\"\n",
    "    if num_gpus == 0:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:CPU:0\")\n",
    "    elif num_gpus == 1:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:GPU:0\")\n",
    "    else:\n",
    "        if all_reduce_alg:\n",
    "            return tf.contrib.distribute.MirroredStrategy(\n",
    "                num_gpus=num_gpus,\n",
    "                cross_tower_ops=tf.contrib.distribute.AllReduceCrossTowerOps(\n",
    "                    all_reduce_alg, num_packs=num_gpus))\n",
    "        else:\n",
    "            return tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Runing Config\n",
    "Load pretrained weight\n",
    "```python\n",
    "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=\"pretrained_model\",\n",
    "                                    vars_to_warm_start=\"vgg16.*\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_tf_random_seed': 2, '_save_summary_steps': 100, '_num_ps_replicas': 0, '_service': None, '_keep_checkpoint_max': 5, '_is_chief': True, '_model_dir': 'model_transfer/', '_save_checkpoints_steps': 100, '_save_checkpoints_secs': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f379e2b8e48>, '_evaluation_master': '', '_log_step_count_steps': 100, '_keep_checkpoint_every_n_hours': 10000, '_master': '', '_train_distribute': None, '_task_type': 'worker', '_device_fn': None, '_global_id_in_cluster': 0, '_task_id': 0, '_session_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 0.8\n",
      "  allow_growth: true\n",
      "}\n",
      ", '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "session_config.gpu_options.allow_growth = True\n",
    "config = tf.estimator.RunConfig(model_dir=model_dir, \n",
    "                                tf_random_seed=seed, \n",
    "                                save_summary_steps=SAVE_SUMMARY_STEPS, \n",
    "                                save_checkpoints_steps=SAVE_SUMMARY_STEPS, \n",
    "                                session_config=session_config,\n",
    "                                keep_checkpoint_max=5, \n",
    "                                log_step_count_steps=100, )\n",
    "#                                train_distribute=get_distribution_strategy(NUM_GPUS)) #for mutiple GPUs\n",
    "ws = tf.estimator.WarmStartSettings(ckpt_to_initialize_from=\"pretrained_model\",\n",
    "                                    vars_to_warm_start=\"vgg16.*\")\n",
    "clf = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, config=config, warm_start_from=ws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 100 or save_checkpoints_secs None.\n",
      "output feature: (?, 128, 128, 3)\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Warm-starting with WarmStartSettings: WarmStartSettings(ckpt_to_initialize_from='pretrained_model', vars_to_warm_start='vgg16.*', var_name_to_vocab_info={}, var_name_to_prev_var_name={})\n",
      "INFO:tensorflow:Warm-starting from: ('pretrained_model',)\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block1_conv2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block1_conv1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv3/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block2_conv2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block1_conv2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block2_conv2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block1_conv1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv3/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block2_conv1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block2_conv1/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block5_conv2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv1/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block3_conv2/kernel; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Warm-starting variable: vgg16/block4_conv2/bias; prev_var_name: Unchanged\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.2870462, step = 0\n",
      "INFO:tensorflow:accuracy = 0.0703125, f1_score_BlackGrass = nan, loss = 3.2870462\n",
      "INFO:tensorflow:Saving checkpoints for 100 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:29:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:29:22\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.20833333, f1_score_BlackGrass = nan, global_step = 100, loss = 2.1883016\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 100: model_transfer/model.ckpt-100\n",
      "INFO:tensorflow:global_step/sec: 0.875453\n",
      "INFO:tensorflow:loss = 2.1715126, step = 100 (114.229 sec)\n",
      "INFO:tensorflow:accuracy = 0.171875, f1_score_BlackGrass = 0.12121212121212122, loss = 2.1715126 (114.230 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 200 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.874187\n",
      "INFO:tensorflow:loss = 1.2944094, step = 200 (114.393 sec)\n",
      "INFO:tensorflow:accuracy = 0.29947916, f1_score_BlackGrass = 0.17241379310344826, loss = 1.2944094 (114.394 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 300 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.888004\n",
      "INFO:tensorflow:loss = 0.736548, step = 300 (112.610 sec)\n",
      "INFO:tensorflow:accuracy = 0.41210938, f1_score_BlackGrass = 0.15584415584415584, loss = 0.736548 (112.610 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 400 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:35:03\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-400\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:35:04\n",
      "INFO:tensorflow:Saving dict for global step 400: accuracy = 0.80833334, f1_score_BlackGrass = 0.6666666666666665, global_step = 400, loss = 0.69463885\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: model_transfer/model.ckpt-400\n",
      "INFO:tensorflow:global_step/sec: 0.870859\n",
      "INFO:tensorflow:loss = 0.7001766, step = 400 (114.831 sec)\n",
      "INFO:tensorflow:accuracy = 0.48359376, f1_score_BlackGrass = 0.2201834862385321, loss = 0.7001766 (114.831 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 500 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.888268\n",
      "INFO:tensorflow:loss = 0.28459817, step = 500 (112.578 sec)\n",
      "INFO:tensorflow:accuracy = 0.5566406, f1_score_BlackGrass = 0.2900763358778626, loss = 0.28459817 (112.578 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 600 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.883398\n",
      "INFO:tensorflow:loss = 0.42828974, step = 600 (113.198 sec)\n",
      "INFO:tensorflow:accuracy = 0.6004464, f1_score_BlackGrass = 0.3229813664596273, loss = 0.42828974 (113.197 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 700 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:40:43\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-700\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:40:44\n",
      "INFO:tensorflow:Saving dict for global step 700: accuracy = 0.89166665, f1_score_BlackGrass = 0.6666666666666666, global_step = 700, loss = 0.4141658\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 700: model_transfer/model.ckpt-700\n",
      "INFO:tensorflow:global_step/sec: 0.875628\n",
      "INFO:tensorflow:loss = 0.30327845, step = 700 (114.204 sec)\n",
      "INFO:tensorflow:accuracy = 0.6376953, f1_score_BlackGrass = 0.3838383838383838, loss = 0.30327845 (114.205 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 800 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.87875\n",
      "INFO:tensorflow:loss = 0.14151895, step = 800 (113.798 sec)\n",
      "INFO:tensorflow:accuracy = 0.6736111, f1_score_BlackGrass = 0.4196428571428571, loss = 0.14151895 (113.800 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 900 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.885034\n",
      "INFO:tensorflow:loss = 0.14282866, step = 900 (112.988 sec)\n",
      "INFO:tensorflow:accuracy = 0.7011719, f1_score_BlackGrass = 0.43724696356275305, loss = 0.14282866 (112.987 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:46:25\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:46:26\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.90833336, f1_score_BlackGrass = 0.7777777777777777, global_step = 1000, loss = 0.35833618\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: model_transfer/model.ckpt-1000\n",
      "INFO:tensorflow:global_step/sec: 0.869643\n",
      "INFO:tensorflow:loss = 0.19108543, step = 1000 (114.991 sec)\n",
      "INFO:tensorflow:accuracy = 0.721946, f1_score_BlackGrass = 0.43076923076923074, loss = 0.19108543 (114.992 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1100 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.884816\n",
      "INFO:tensorflow:loss = 0.106124304, step = 1100 (113.018 sec)\n",
      "INFO:tensorflow:accuracy = 0.7421875, f1_score_BlackGrass = 0.4555160142348754, loss = 0.106124304 (113.018 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1200 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.883072\n",
      "INFO:tensorflow:loss = 0.16672018, step = 1200 (113.241 sec)\n",
      "INFO:tensorflow:accuracy = 0.75691104, f1_score_BlackGrass = 0.4777070063694268, loss = 0.16672018 (113.240 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1300 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:52:06\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1300\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:52:07\n",
      "INFO:tensorflow:Saving dict for global step 1300: accuracy = 0.94166666, f1_score_BlackGrass = 0.888888888888889, global_step = 1300, loss = 0.3127513\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1300: model_transfer/model.ckpt-1300\n",
      "INFO:tensorflow:global_step/sec: 0.871031\n",
      "INFO:tensorflow:loss = 0.12425931, step = 1300 (114.807 sec)\n",
      "INFO:tensorflow:accuracy = 0.77064735, f1_score_BlackGrass = 0.5057471264367817, loss = 0.12425931 (114.810 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1400 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.88529\n",
      "INFO:tensorflow:loss = 0.17100605, step = 1400 (112.958 sec)\n",
      "INFO:tensorflow:accuracy = 0.7838542, f1_score_BlackGrass = 0.5376344086021506, loss = 0.17100605 (112.956 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1500 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.882091\n",
      "INFO:tensorflow:loss = 0.06914896, step = 1500 (113.367 sec)\n",
      "INFO:tensorflow:accuracy = 0.795166, f1_score_BlackGrass = 0.5454545454545454, loss = 0.06914896 (113.367 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1600 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-01:57:47\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1600\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-01:57:47\n",
      "INFO:tensorflow:Saving dict for global step 1600: accuracy = 0.9583333, f1_score_BlackGrass = 0.9090909090909091, global_step = 1600, loss = 0.23647246\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1600: model_transfer/model.ckpt-1600\n",
      "INFO:tensorflow:global_step/sec: 0.876563\n",
      "INFO:tensorflow:loss = 0.06319009, step = 1600 (114.081 sec)\n",
      "INFO:tensorflow:accuracy = 0.80629593, f1_score_BlackGrass = 0.580046403712297, loss = 0.06319009 (114.081 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1700 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:global_step/sec: 0.888196\n",
      "INFO:tensorflow:loss = 0.11781836, step = 1700 (112.593 sec)\n",
      "INFO:tensorflow:accuracy = 0.8151042, f1_score_BlackGrass = 0.5943600867678959, loss = 0.11781836 (112.596 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1800 into model_transfer/model.ckpt.\n",
      "INFO:tensorflow:Skip the current checkpoint eval due to throttle secs (300 secs).\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-17-02:01:34\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-17-02:01:35\n",
      "INFO:tensorflow:Saving dict for global step 1800: accuracy = 0.98333335, f1_score_BlackGrass = 0.9473684210526316, global_step = 1800, loss = 0.24913336\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1800: model_transfer/model.ckpt-1800\n",
      "INFO:tensorflow:Loss for final step: 0.08257436.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'accuracy': 0.98333335,\n",
       "  'f1_score_BlackGrass': 0.9473684210526316,\n",
       "  'global_step': 1800,\n",
       "  'loss': 0.24913336},\n",
       " [])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_spec = tf.estimator.TrainSpec(lambda:train_input_fn_keras(generator), max_steps=1800)\n",
    "eval_spec = tf.estimator.EvalSpec(lambda:eval_input_fn(valid_dataset, valid_labels), throttle_secs=300)\n",
    "tf.estimator.train_and_evaluate(clf, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for Tensorflow Serving\n",
    "Can not save model after **predict**, because `Graph` is finalized and cannot be modified  \n",
    "You can assign which model to be saved by `checkpoint_path` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['serving_default', 'classify']\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n",
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1800\n",
      "INFO:tensorflow:Assets added to graph.\n",
      "INFO:tensorflow:No assets to write.\n",
      "INFO:tensorflow:SavedModel written to: saved_model/temp-b'1537149952'/saved_model.pb\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "b'saved_model/1537149952'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input\n",
    "image = tf.placeholder(tf.float32, shape=[None, 128, 128, 3], name='image')\n",
    "# input receiver\n",
    "input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "    'image': image,\n",
    "})\n",
    "\n",
    "clf.export_savedmodel(\"saved_model/\", input_fn, checkpoint_path=\"model_transfer/model.ckpt-1800\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and predict\n",
    "Estimator predict method return **generator** type, so if you want to get all predictions please use for loop  \n",
    "```python\n",
    "for result in results:\n",
    "    print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Input graph does not use tf.data.Dataset or contain a QueueRunner. That means predict yields forever. This is probably a mistake.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from model_transfer/model.ckpt-1800\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_ids': array([8]),\n",
       " 'logits': array([-1.4777876e+00, -6.1166072e+00, -3.3255301e+00,  5.0885554e-02,\n",
       "        -4.0424337e+00, -1.0114145e+00, -9.4042438e-01,  4.2232685e-03,\n",
       "         1.3058451e+01,  2.5360951e+00, -5.3657331e+00, -2.9324665e+00],\n",
       "       dtype=float32),\n",
       " 'probability': array([4.8638162e-07, 4.7028741e-09, 7.6650210e-08, 2.2432178e-06,\n",
       "        3.7425366e-08, 7.7539067e-07, 8.3243702e-07, 2.1409487e-06,\n",
       "        9.9996638e-01, 2.6926768e-05, 9.9647046e-09, 1.1355815e-07],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = clf.predict(lambda: eval_input_fn(valid_dataset, valid_labels), checkpoint_path=\"model_transfer/model.ckpt-1800\")\n",
    "next(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from `Estimator.export_savedmodel`\n",
    "Reference: https://qiita.com/parkkiung123/items/13adb482860f356f97f3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1537149952/variables/variables\n",
      "[ 8  8  8  8  8  8  8  8  8  8 11 11 11 11 11 11 11 11 11 11  4  4  4  4\n",
      "  4  4  4  4  4  4  1  1  1  1  1  1  1  1  1  1 10 10 10 10 10 10 10 10\n",
      " 10 10  6  6  6  6  6  6  6  6  6  6  7  7  7  7  7  7  7  7  7  7  9  9\n",
      "  9  9  9  9  9  9  9  9  3  3  3  3  3  3  3  3  3  3  5  5  5  5  5  5\n",
      "  5  5  5  5  2  2  2  3  2  2  2  2  2  2  0  0  0  0  0  0  0  0  0  6]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "export_dir = 'saved_model/1537149952'\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # saved_model load\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # input\n",
    "    i = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "    # output\n",
    "    r = sess.graph.get_tensor_by_name(\"ArgMax:0\")\n",
    "    print(sess.run(r, feed_dict={i:valid_dataset}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN Visualization\n",
    "Reference: https://github.com/InFoCusp/tf_cnnvis  \n",
    "Although you put multiple images, it only draws one image for visulization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1537149952/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for vgg16/block1_conv1/Relu layer. Time taken = 0.349250 s\n",
      "Reconstruction Completed for vgg16/block1_conv2/Relu layer. Time taken = 0.277605 s\n",
      "Reconstruction Completed for vgg16/block2_conv1/Relu layer. Time taken = 0.128750 s\n",
      "Reconstruction Completed for vgg16/block2_conv2/Relu layer. Time taken = 0.173343 s\n",
      "Reconstruction Completed for vgg16/block3_conv1/Relu layer. Time taken = 0.111904 s\n",
      "Reconstruction Completed for vgg16/block3_conv2/Relu layer. Time taken = 0.120182 s\n",
      "Reconstruction Completed for vgg16/block3_conv3/Relu layer. Time taken = 0.096687 s\n",
      "Reconstruction Completed for vgg16/block4_conv1/Relu layer. Time taken = 0.094324 s\n",
      "Reconstruction Completed for vgg16/block4_conv2/Relu layer. Time taken = 0.090897 s\n",
      "Reconstruction Completed for vgg16/block4_conv3/Relu layer. Time taken = 0.070399 s\n",
      "Reconstruction Completed for vgg16/block5_conv1/Relu layer. Time taken = 0.076568 s\n",
      "Reconstruction Completed for vgg16/block5_conv2/Relu layer. Time taken = 0.062248 s\n",
      "Reconstruction Completed for vgg16/block5_conv3/Relu layer. Time taken = 0.049159 s\n",
      "Reconstruction Completed for fine_tune/dense1/Relu layer. Time taken = 0.066381 s\n",
      "Reconstruction Completed for fine_tune/dense2/Relu layer. Time taken = 0.054745 s\n",
      "Reconstruction Completed for vgg16/block1_pool/MaxPool layer. Time taken = 0.085853 s\n",
      "Reconstruction Completed for vgg16/block2_pool/MaxPool layer. Time taken = 0.070054 s\n",
      "Reconstruction Completed for vgg16/block3_pool/MaxPool layer. Time taken = 0.053803 s\n",
      "Reconstruction Completed for vgg16/block4_pool/MaxPool layer. Time taken = 0.070740 s\n",
      "Reconstruction Completed for vgg16/block5_pool/MaxPool layer. Time taken = 0.067270 s\n",
      "Reconstruction Completed for vgg16/block1_conv1/Conv2D layer. Time taken = 0.373786 s\n",
      "Reconstruction Completed for vgg16/block1_conv2/Conv2D layer. Time taken = 0.281343 s\n",
      "Reconstruction Completed for vgg16/block2_conv1/Conv2D layer. Time taken = 0.103038 s\n",
      "Reconstruction Completed for vgg16/block2_conv2/Conv2D layer. Time taken = 0.109982 s\n",
      "Reconstruction Completed for vgg16/block3_conv1/Conv2D layer. Time taken = 0.080624 s\n",
      "Reconstruction Completed for vgg16/block3_conv2/Conv2D layer. Time taken = 0.086062 s\n",
      "Reconstruction Completed for vgg16/block3_conv3/Conv2D layer. Time taken = 0.076716 s\n",
      "Reconstruction Completed for vgg16/block4_conv1/Conv2D layer. Time taken = 0.063288 s\n",
      "Reconstruction Completed for vgg16/block4_conv2/Conv2D layer. Time taken = 0.072538 s\n",
      "Reconstruction Completed for vgg16/block4_conv3/Conv2D layer. Time taken = 0.074104 s\n",
      "Reconstruction Completed for vgg16/block5_conv1/Conv2D layer. Time taken = 0.056858 s\n",
      "Reconstruction Completed for vgg16/block5_conv2/Conv2D layer. Time taken = 0.053190 s\n",
      "Reconstruction Completed for vgg16/block5_conv3/Conv2D layer. Time taken = 0.062435 s\n",
      "Total Time = 4.161851\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "# activation visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # with sess_graph_path = None, the default Session will be used for visualization.\n",
    "    is_success = tf_cnnvis.activation_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                    layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                    path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from saved_model/1537149952/variables/variables\n",
      "INFO:tensorflow:Restoring parameters from model/tmp-model\n",
      "Reconstruction Completed for vgg16/block1_conv1/Relu layer. Time taken = 0.518571 s\n",
      "Reconstruction Completed for vgg16/block1_conv2/Relu layer. Time taken = 0.984730 s\n",
      "Reconstruction Completed for vgg16/block2_conv1/Relu layer. Time taken = 1.556450 s\n",
      "Reconstruction Completed for vgg16/block2_conv2/Relu layer. Time taken = 2.120039 s\n",
      "Reconstruction Completed for vgg16/block3_conv1/Relu layer. Time taken = 4.688469 s\n",
      "Reconstruction Completed for vgg16/block3_conv2/Relu layer. Time taken = 4.956059 s\n",
      "Reconstruction Completed for vgg16/block3_conv3/Relu layer. Time taken = 4.699175 s\n",
      "Reconstruction Completed for vgg16/block4_conv1/Relu layer. Time taken = 9.097654 s\n",
      "Reconstruction Completed for vgg16/block4_conv2/Relu layer. Time taken = 7.496255 s\n",
      "Reconstruction Completed for vgg16/block4_conv3/Relu layer. Time taken = 6.963719 s\n",
      "Reconstruction Completed for vgg16/block5_conv1/Relu layer. Time taken = 9.958946 s\n",
      "Reconstruction Completed for vgg16/block5_conv2/Relu layer. Time taken = 9.236637 s\n",
      "Reconstruction Completed for vgg16/block5_conv3/Relu layer. Time taken = 6.224679 s\n",
      "Reconstruction Completed for fine_tune/dense1/Relu layer. Time taken = 5.548175 s\n",
      "Reconstruction Completed for fine_tune/dense2/Relu layer. Time taken = 4.299212 s\n",
      "Reconstruction Completed for vgg16/block1_pool/MaxPool layer. Time taken = 2.282595 s\n",
      "Reconstruction Completed for vgg16/block2_pool/MaxPool layer. Time taken = 3.473423 s\n",
      "Reconstruction Completed for vgg16/block3_pool/MaxPool layer. Time taken = 5.391582 s\n",
      "Reconstruction Completed for vgg16/block4_pool/MaxPool layer. Time taken = 7.160118 s\n",
      "Reconstruction Completed for vgg16/block5_pool/MaxPool layer. Time taken = 7.526316 s\n",
      "Reconstruction Completed for vgg16/block1_conv1/Conv2D layer. Time taken = 2.251566 s\n",
      "Reconstruction Completed for vgg16/block1_conv2/Conv2D layer. Time taken = 2.822265 s\n",
      "Reconstruction Completed for vgg16/block2_conv1/Conv2D layer. Time taken = 3.433980 s\n",
      "Reconstruction Completed for vgg16/block2_conv2/Conv2D layer. Time taken = 3.693009 s\n",
      "Reconstruction Completed for vgg16/block3_conv1/Conv2D layer. Time taken = 4.957700 s\n",
      "Reconstruction Completed for vgg16/block3_conv2/Conv2D layer. Time taken = 5.871186 s\n",
      "Reconstruction Completed for vgg16/block3_conv3/Conv2D layer. Time taken = 5.915181 s\n",
      "Reconstruction Completed for vgg16/block4_conv1/Conv2D layer. Time taken = 11.361437 s\n",
      "Reconstruction Completed for vgg16/block4_conv2/Conv2D layer. Time taken = 10.791737 s\n",
      "Reconstruction Completed for vgg16/block4_conv3/Conv2D layer. Time taken = 12.530464 s\n",
      "Reconstruction Completed for vgg16/block5_conv1/Conv2D layer. Time taken = 13.855274 s\n",
      "Reconstruction Completed for vgg16/block5_conv2/Conv2D layer. Time taken = 14.953552 s\n",
      "Reconstruction Completed for vgg16/block5_conv3/Conv2D layer. Time taken = 14.906800 s\n",
      "Total Time = 212.393785\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from tf_cnnvis import tf_cnnvis\n",
    "\n",
    "# deconv visualization\n",
    "layers = ['r', 'p', 'c']\n",
    "\n",
    "start = time.time()\n",
    "image = sess.graph.get_tensor_by_name(\"image:0\")\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    is_success = tf_cnnvis.deconv_visualization(sess_graph_path = None, value_feed_dict = {image : valid_dataset[10:11]}, \n",
    "                                                layers=layers, path_logdir=os.path.join(\"Log\",\"VGGNet\"), \n",
    "                                                path_outdir=os.path.join(\"Output\",\"VGGNet\"))\n",
    "start = time.time() - start\n",
    "print(\"Total Time = %f\" % (start))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
