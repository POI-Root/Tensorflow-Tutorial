{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This tutorial is running on Geforce GTX 1080Ti 12GB\n",
    "Generator learn how to draw after about 50 epochs, so be patient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Basic Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Environment and Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0' # use first GPU\n",
    "\n",
    "seed = 2 # random seed\n",
    "model_dir = \"model_InfoGAN/\" # folder for saving model and log\n",
    "BATCH_SIZE = 1024 # number of images in one batch\n",
    "CATEGORICAL_LATENT_SIZE = 10 # size of categorical latent code\n",
    "CONTINUOUS_LATENT_SIZE = 2 # size of continuous latent code\n",
    "NOISE_DIM = 62 # noise dimension for generator\n",
    "EPOCHS = 300\n",
    "SAVE_SUMMARY_STEPS = 100 # save summary to tensorboard - one step means one batch\n",
    "NUM_GPUS = 1 # number of GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data\n",
    "Use MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(image, label),(_, _)  = tf.keras.datasets.mnist.load_data()\n",
    "image = np.expand_dims(image, axis=-1)\n",
    "label = np.expand_dims(label, axis=-1)\n",
    "print(\"Image shape:\", image.shape)\n",
    "print(\"Label shape:\", label.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Training Data to Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_input_fn(images, labels):\n",
    "    \n",
    "    def make_generator(images, labels):\n",
    "\n",
    "        def _generator():\n",
    "            for image, label in zip(images, labels):\n",
    "                yield image, label\n",
    "\n",
    "        return _generator\n",
    "    \n",
    "    # Normalize the values of the image from [0, 255] to [-1.0, 1.0]\n",
    "    def _preprocessing(image, label):\n",
    "        image = image * (2.0 / 255.0) - 1.0\n",
    "        return image, label\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_generator(make_generator(images, labels), (tf.float32, tf.float32))\n",
    "    dataset = dataset.shuffle(buffer_size=10000)\n",
    "    dataset = dataset.repeat(EPOCHS)\n",
    "    dataset = dataset.map(_preprocessing)\n",
    "    dataset = dataset.batch(BATCH_SIZE, drop_remainder=True)\n",
    "    dataset = dataset.prefetch(None)\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    images, labels = iterator.get_next()\n",
    "    images = tf.reshape(images, [-1, 28, 28, 1])\n",
    "    print(\"output image:\", images.shape)\n",
    "    \n",
    "    tf.summary.image(\"images\", images)\n",
    "    \n",
    "    # create categorical, continious and random noises\n",
    "    c_cat = tf.one_hot(np.random.randint(0, CATEGORICAL_LATENT_SIZE, size=[BATCH_SIZE]), depth=CATEGORICAL_LATENT_SIZE, dtype=tf.float32)\n",
    "    c_cont = tf.random_normal(shape=(BATCH_SIZE, CONTINUOUS_LATENT_SIZE))\n",
    "    random_noises = tf.random_normal(shape=(BATCH_SIZE, NOISE_DIM))\n",
    "    \n",
    "    features = {\"images\": images,\n",
    "                \"c_cat\": c_cat,\n",
    "                \"c_cont\": c_cont,\n",
    "                \"random_noises\": random_noises}\n",
    "    \n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed Random Noise Data to Model for Eval and Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_noise_input_fn():\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    c_cat = tf.one_hot([3 for i in range(10)], depth=10, dtype=tf.float32)\n",
    "    c_cont = tf.constant([[i, 0.0] for i in np.linspace(-2, 2, num=10, dtype=np.float32)])\n",
    "    \n",
    "    dataset = tf.data.Dataset.from_tensors(tf.constant(np.random.randn(10, NOISE_DIM), dtype=tf.float32))\n",
    "    \n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    \n",
    "    noises = iterator.get_next()\n",
    "    \n",
    "    return {\"random_noises\": noises, \"c_cat\": c_cat, \"c_cont\": c_cont}, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Structure\n",
    "**Remember: Do batch normalization in training mode, but not in evaluation and prediction mode**  \n",
    "This model Structure based on DCGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(c_cat, c_cont, noise, training):\n",
    "    \n",
    "    with tf.variable_scope(\"generator\", reuse=tf.AUTO_REUSE):\n",
    "        vectors = tf.concat([c_cat, c_cont, noise], axis=-1)\n",
    "        with tf.variable_scope(\"block1\"):\n",
    "            vectors = tf.layers.dense(vectors, units=1024, name=\"dense\")\n",
    "            vectors = tf.layers.batch_normalization(vectors, training=training, name=\"batch_normalization\")\n",
    "            vectors = tf.nn.relu(vectors, name=\"relu\")\n",
    "        with tf.variable_scope(\"block2\"):\n",
    "            vectors = tf.layers.dense(vectors, units=7*7*128, name=\"dense\")\n",
    "            vectors = tf.layers.batch_normalization(vectors, training=training, name=\"batch_normalization\")\n",
    "            vectors = tf.nn.relu(vectors, name=\"relu\")\n",
    "        images = tf.reshape(vectors, [-1, 7, 7, 128])\n",
    "        with tf.variable_scope(\"block3\"):\n",
    "            images = tf.layers.conv2d_transpose(images, filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", name=\"deconv\")\n",
    "            images = tf.layers.batch_normalization(images, training=training, name=\"batch_normalization\")\n",
    "            images = tf.nn.relu(images, name=\"relu\")\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            images = tf.layers.conv2d_transpose(images, filters=1, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", name=\"deconv\")\n",
    "            images = tf.nn.tanh(images, name=\"tanh\")\n",
    "            \n",
    "        return images\n",
    "    \n",
    "def discriminator(images, c_cat, c_cont, training):\n",
    "    \n",
    "    with tf.variable_scope(\"discriminator\", reuse=tf.AUTO_REUSE):\n",
    "        with tf.variable_scope(\"block1\"):\n",
    "            images = tf.layers.conv2d(images, filters=64, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", name=\"conv\")\n",
    "            images = tf.layers.batch_normalization(images, training=training, name=\"batch_normalization\")\n",
    "            images = tf.nn.leaky_relu(images, alpha=0.2, name=\"leaky_relu\")\n",
    "        with tf.variable_scope(\"block2\"):\n",
    "            images = tf.layers.conv2d(images, filters=128, kernel_size=(4, 4), strides=(2, 2), padding=\"same\", name=\"conv\")\n",
    "            images = tf.layers.batch_normalization(images, training=training, name=\"batch_normalization\")\n",
    "            images = tf.nn.leaky_relu(images, alpha=0.2, name=\"leaky_relu\")\n",
    "        vectors = tf.layers.flatten(images, name=\"flatten\")\n",
    "        with tf.variable_scope(\"block3\"):\n",
    "            vectors = tf.layers.dense(vectors, units=1024, name=\"dense\")\n",
    "            vectors = tf.layers.batch_normalization(vectors, training=training, name=\"batch_normalization\")\n",
    "            vectors = tf.nn.leaky_relu(vectors, alpha=0.2, name=\"leaky_relu\")\n",
    "        with tf.variable_scope(\"output\"):\n",
    "            values = tf.layers.dense(vectors, units=1, name=\"dense\")\n",
    "        with tf.variable_scope(\"latent_code\"):\n",
    "            with tf.variable_scope(\"block1\"):\n",
    "                    code = tf.layers.dense(vectors, units=128, name=\"dense\")\n",
    "                    code = tf.layers.batch_normalization(code, training=training, name=\"batch_normalization\")\n",
    "                    code = tf.nn.leaky_relu(code, alpha=0.2, name=\"leaky_relu\")\n",
    "            with tf.variable_scope(\"categorical\"):\n",
    "                cat = tf.layers.dense(code, units=CATEGORICAL_LATENT_SIZE, name=\"dense\")\n",
    "            with tf.variable_scope(\"continuous\"):\n",
    "                with tf.variable_scope(\"mean\"):\n",
    "                    mean = tf.layers.dense(code, units=CONTINUOUS_LATENT_SIZE, name=\"dense\")\n",
    "                with tf.variable_scope(\"log_std\"):\n",
    "                    log_std = tf.layers.dense(code, units=CONTINUOUS_LATENT_SIZE, name=\"dense\")\n",
    "    return values, cat, mean, log_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Function for tf.Estimator\n",
    "To save model for tensorflow serving, set **`export_outputs`** parameter in prediction mode   \n",
    "Mutual Information Implementation: https://github.com/tdeboissiere/DeepLearningImplementations/issues/47  \n",
    "**Note:**    \n",
    "**1. Add mutual information to generator and discriminator**  \n",
    "**2. Careful choosing learning rate**   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_fn(features, labels, mode):\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        training = True\n",
    "    else:\n",
    "        training = False\n",
    "    \n",
    "    fake_images = generator(features[\"c_cat\"], features[\"c_cont\"], features[\"random_noises\"], training)\n",
    "    \n",
    "    # Prediction mode for tensorflow serving\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "        predictions = {\n",
    "            \"images\": fake_images\n",
    "        }\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions, export_outputs={ \n",
    "            'output': tf.estimator.export.PredictOutput(predictions)})\n",
    "    \n",
    "    fake_values, cat, mean, log_std = discriminator(fake_images, features[\"c_cat\"], features[\"c_cont\"], training)\n",
    "    \n",
    "    # calculate cross entropy loss   \n",
    "    discriminator_fake_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.zeros_like(fake_values), logits=fake_values, scope=\"discriminator_fake_loss\")\n",
    "    generator_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(fake_values), logits=fake_values, scope=\"generator_loss\")\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "        \n",
    "        real_images = features[\"images\"]\n",
    "        real_values, _, _, _ = discriminator(real_images, features[\"c_cat\"], features[\"c_cont\"], training)\n",
    "        \n",
    "        discriminator_real_loss = tf.losses.sigmoid_cross_entropy(multi_class_labels=tf.ones_like(real_values), logits=real_values, scope=\"discriminator_real_loss\")\n",
    "        discriminator_loss = tf.add(discriminator_real_loss, discriminator_fake_loss, name=\"discriminator_loss\")\n",
    "        \n",
    "        # mutual information\n",
    "        cat_loss = tf.losses.softmax_cross_entropy(onehot_labels=features[\"c_cat\"], logits=cat, scope=\"categorical_loss\")\n",
    "        tf.summary.scalar(\"categorical_loss\", cat_loss)\n",
    "        cont_loss = tf.reduce_mean(tf.reduce_sum(log_std + 0.5 * tf.square((features[\"c_cont\"] - mean) / (tf.exp(log_std) + 1e-7)), axis=1), name=\"continuous_loss\")\n",
    "        tf.summary.scalar(\"continuous_loss\", cont_loss)\n",
    "        mutual_information_loss = tf.add(cat_loss, cont_loss, name=\"mutual_information_loss\")\n",
    "        tf.summary.scalar(\"mutual_information_loss\", mutual_information_loss)\n",
    "        \n",
    "        discriminator_loss += mutual_information_loss\n",
    "        generator_loss += mutual_information_loss\n",
    "        tf.summary.scalar(\"discriminator_loss\", discriminator_loss)\n",
    "        \n",
    "        # optimizer\n",
    "        lr = tf.train.exponential_decay(0.0002, tf.train.get_global_step(), 500, 0.95)\n",
    "        tf.summary.scalar(\"learning_rate\", lr)\n",
    "        generator_optimizer = tf.train.AdamOptimizer(learning_rate=0.001, beta1=0.5)\n",
    "        discriminator_optimizer = tf.train.AdamOptimizer(learning_rate=0.0002, beta1=0.5)\n",
    "        \n",
    "        # for batch normalization, tell tensorflow update batch normalization mean and variance\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            # training variable\n",
    "            var_list=tf.trainable_variables()\n",
    "            generator_var = [var for var in var_list if \"generator\" in var.name]\n",
    "            discriminator_var = [var for var in var_list if \"discriminator\" in var.name]\n",
    "            \n",
    "            # training operation\n",
    "            discriminator_train_op = discriminator_optimizer.minimize(discriminator_loss, var_list=discriminator_var)\n",
    "            generator_train_op = generator_optimizer.minimize(generator_loss, var_list=generator_var)\n",
    "        \n",
    "        step = tf.assign_add(tf.train.get_or_create_global_step(), 1)\n",
    "        train_op = tf.group([discriminator_train_op, generator_train_op, step])\n",
    "        \n",
    "        # monitor trianing information\n",
    "        logging_hook = tf.train.LoggingTensorHook({\"generator_loss\": generator_loss,\n",
    "                                                   \"discriminator_loss\": discriminator_loss,\n",
    "                                                   \"mutual_information_loss\": mutual_information_loss}, \n",
    "                                                  every_n_iter=SAVE_SUMMARY_STEPS)\n",
    "        \n",
    "        return tf.estimator.EstimatorSpec(mode, loss=generator_loss, train_op=train_op, training_hooks=[logging_hook])\n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.EVAL:\n",
    "        tf.summary.image(\"fake_images\", fake_images, max_outputs=10)\n",
    "        eval_summary_hook = tf.train.SummarySaverHook(\n",
    "                                save_steps=1,\n",
    "                                output_dir=model_dir + \"/eval_summary\",\n",
    "                                summary_op=tf.summary.merge_all())\n",
    "        metrics = {\"discriminator_fake_loss\" : tf.metrics.mean(discriminator_fake_loss)}\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=generator_loss, eval_metric_ops=metrics, evaluation_hooks=[eval_summary_hook])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For Multiple GPU (Parallel Computing)\n",
    "Testing, not stable version  \n",
    "Evaluation is not yet distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distribution_strategy(num_gpus, all_reduce_alg=None):\n",
    "    \"\"\"Return a DistributionStrategy for running the model.\n",
    "    Args:\n",
    "    num_gpus: Number of GPUs to run this model.\n",
    "    all_reduce_alg: Specify which algorithm to use when performing all-reduce.\n",
    "      See tf.contrib.distribute.AllReduceCrossTowerOps for available algorithms.\n",
    "      If None, DistributionStrategy will choose based on device topology.\n",
    "    Returns:\n",
    "    tf.contrib.distribute.DistibutionStrategy object.\n",
    "    \"\"\"\n",
    "    if num_gpus == 0:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:CPU:0\")\n",
    "    elif num_gpus == 1:\n",
    "        return tf.contrib.distribute.OneDeviceStrategy(\"device:GPU:0\")\n",
    "    else:\n",
    "        if all_reduce_alg:\n",
    "            return tf.contrib.distribute.MirroredStrategy(\n",
    "                num_gpus=num_gpus,\n",
    "                cross_tower_ops=tf.contrib.distribute.AllReduceCrossTowerOps(\n",
    "                    all_reduce_alg, num_packs=num_gpus))\n",
    "        else:\n",
    "            return tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Runing Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session_config = tf.ConfigProto()\n",
    "session_config.gpu_options.per_process_gpu_memory_fraction = 0.8\n",
    "session_config.gpu_options.allow_growth = True\n",
    "config = tf.estimator.RunConfig(model_dir=model_dir, \n",
    "                                tf_random_seed=seed, \n",
    "                                save_summary_steps=SAVE_SUMMARY_STEPS, \n",
    "                                save_checkpoints_steps=SAVE_SUMMARY_STEPS, \n",
    "                                session_config=session_config,\n",
    "                                keep_checkpoint_max=5, \n",
    "                                log_step_count_steps=SAVE_SUMMARY_STEPS, )\n",
    "#                                train_distribute=get_distribution_strategy(NUM_GPUS)) #for mutiple GPUs\n",
    "clf = tf.estimator.Estimator(model_fn=model_fn, model_dir=model_dir, config=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train and Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_spec = tf.estimator.TrainSpec(lambda:train_input_fn(image, label), max_steps=18000)\n",
    "eval_spec = tf.estimator.EvalSpec(lambda:random_noise_input_fn(), throttle_secs=1)\n",
    "tf.estimator.train_and_evaluate(clf, train_spec, eval_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save model for Tensorflow Serving\n",
    "Can not save model after **predict**, because `Graph` is finalized and cannot be modified  \n",
    "You can assign which model to be saved by `checkpoint_path` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input\n",
    "c_cat = tf.placeholder(tf.float32, shape=[None, CATEGORICAL_LATENT_SIZE], name=\"c_cat\")\n",
    "c_cont = tf.placeholder(tf.float32, shape=[None, CONTINUOUS_LATENT_SIZE], name=\"c_cont\")\n",
    "vector = tf.placeholder(tf.float32, shape=[None, NOISE_DIM], name='random_noises')\n",
    "# input receiver\n",
    "input_fn = tf.estimator.export.build_raw_serving_input_receiver_fn({\n",
    "    'c_cat': c_cat,\n",
    "    'c_cont': c_cont,\n",
    "    'random_noises': vector\n",
    "})\n",
    "\n",
    "clf.export_savedmodel(\"saved_model/\", input_fn, checkpoint_path=\"model_InfoGAN/model.ckpt-17579\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model and predict\n",
    "Estimator predict method return **generator** type, so if you want to get all predictions please use for loop  \n",
    "```python\n",
    "for result in results:\n",
    "    print(result)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "results = clf.predict(lambda: random_noise_input_fn(), checkpoint_path=\"model_InfoGAN/model.ckpt-17579\")\n",
    "for result in results:\n",
    "    plt.imshow(result[\"images\"][:,:,0])\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from `Estimator.export_savedmodel`\n",
    "Reference: https://qiita.com/parkkiung123/items/13adb482860f356f97f3  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "export_dir = 'saved_model/1538095337'\n",
    "\n",
    "with tf.Session(graph=tf.Graph()) as sess:\n",
    "    # saved_model load\n",
    "    tf.saved_model.loader.load(sess, [tf.saved_model.tag_constants.SERVING], export_dir)\n",
    "    # print all tensor name\n",
    "#     for op in sess.graph.get_operations():\n",
    "#         print(op.values())\n",
    "    # input\n",
    "    i = sess.graph.get_tensor_by_name(\"random_noises:0\")\n",
    "    cat = sess.graph.get_tensor_by_name(\"c_cat:0\")\n",
    "    cont = sess.graph.get_tensor_by_name(\"c_cont:0\")\n",
    "    # output\n",
    "    r = sess.graph.get_tensor_by_name(\"generator/output/tanh:0\")\n",
    "    image = sess.run(r, feed_dict={i:np.random.randn(1, NOISE_DIM), cat:[[0, 1, 0, 0, 0, 0, 0, 0, 0, 0]], cont:[[0, 0]]})\n",
    "    print(image.shape)\n",
    "    plt.imshow(image[0][:,:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
